# Install the Kaggle API
!pip install kaggle

# Make a directory for the Kaggle API credentials
!mkdir -p ~/.kaggle

# Upload the kaggle.json file to your environment
# This is an interactive step where you need to upload the kaggle.json file manually in Colab.
from google.colab import files
uploaded = files.upload()

# Move the kaggle.json file to the appropriate directory
!cp kaggle.json ~/.kaggle/

# Set the permissions for the kaggle.json file
!chmod 600 ~/.kaggle/kaggle.json

# Download the dataset using the Kaggle API
!kaggle datasets download -d gti-upm/leapgestrecog

# Unzip the dataset
!unzip -q leapgestrecog.zip -d leapgestrecog

# Verify the directory structure
!ls leapgestrecog

# Check the contents of the main directory
!ls leapgestrecog

# Check the contents of the inner directories
!ls leapgestrecog/leapGestRecog



import os
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
import cv2
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Path to dataset
data_dir = 'leapgestrecog/leapGestRecog'

# Verify the directory structure
print("Main directory contents:")
print(os.listdir(data_dir))

# Load the images and labels
images = []
labels = []

# Adjust this loop based on the actual directory structure
for folder in os.listdir(data_dir):
    folder_path = os.path.join(data_dir, folder)
    if os.path.isdir(folder_path):
        for label in os.listdir(folder_path):
            label_path = os.path.join(folder_path, label)
            for img_file in os.listdir(label_path):
                img_path = os.path.join(label_path, img_file)
                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                img = cv2.resize(img, (128, 128))  # Resize to 128x128
                images.append(img)
                labels.append(label)
    else:
        print(f"Folder {folder_path} does not exist.")

if not images or not labels:
    print("No images or labels found. Check the dataset path and structure.")
else:
    images = np.array(images)
    labels = np.array(labels)

    # Normalize images
    images = images / 255.0

    # Encode labels
    le = LabelEncoder()
    labels = le.fit_transform(labels)
    labels = to_categorical(labels)

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)

    # Add channel dimension
    X_train = np.expand_dims(X_train, axis=-1)
    X_test = np.expand_dims(X_test, axis=-1)

    # Build the model
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(len(le.classes_), activation='softmax')
    ])

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    model.summary()

    # Train the model
    history = model.fit(X_train, y_train, epochs=10, validation_split=0.2, batch_size=32)

    # Evaluate the model
    test_loss, test_acc = model.evaluate(X_test, y_test)
    print(f"Test accuracy: {test_acc}")

    # Save the model
    model.save('hand_gesture_recognition_model.h5')

    # Function to make predictions
    def predict_gesture(image_path):
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (128, 128))
        img = img / 255.0
        img = np.expand_dims(img, axis=[0, -1])
        prediction = model.predict(img)
        predicted_class = le.inverse_transform([np.argmax(prediction)])
        return predicted_class[0]

    #  usage
    print(predict_gesture('path_to_new_image.png'))
